{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12025869,"sourceType":"datasetVersion","datasetId":7566230},{"sourceId":243059908,"sourceType":"kernelVersion"},{"sourceId":421259,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":343315,"modelId":364597}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport numpy as np\nfrom datasets import load_dataset\nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-25T12:57:48.650396Z","iopub.execute_input":"2025-06-25T12:57:48.650783Z","iopub.status.idle":"2025-06-25T12:57:54.446726Z","shell.execute_reply.started":"2025-06-25T12:57:48.650747Z","shell.execute_reply":"2025-06-25T12:57:54.445836Z"},"id":"kJt1cuRPm93-"},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install --upgrade datasets\ndataset = load_dataset(\"cnn_dailymail\",\"3.0.0\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T12:59:37.297903Z","iopub.execute_input":"2025-06-25T12:59:37.298740Z","iopub.status.idle":"2025-06-25T12:59:55.033032Z","shell.execute_reply.started":"2025-06-25T12:59:37.298703Z","shell.execute_reply":"2025-06-25T12:59:55.032411Z"},"id":"PJnUKhUvm93_","colab":{"base_uri":"https://localhost:8080/"},"outputId":"352d9285-f547-420f-d474-737f1276cf6c"},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nCollecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.18)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\nDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: fsspec\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.9.0.13 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.4.0.6 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.10.19 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.4.40 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.9.5 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.9.41 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed fsspec-2025.3.0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b03fbba0b4b42589e027575bda31178"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00003.parquet:   0%|          | 0.00/257M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b0d33bf96f84341932d8810e01a008a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00001-of-00003.parquet:   0%|          | 0.00/257M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fe6a348126844c8aa1f1ccb66570409"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00002-of-00003.parquet:   0%|          | 0.00/259M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf430505f5764eacac42a04a7991f123"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/34.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14eaf996dcc5421da07a21bbde5bb1ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/30.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdfc837f30b54008875a32e49e8b9c3d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/287113 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c20900bfc16742ba887ab4e3d8cd6fab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/13368 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9da51121f5d465b9913a9a0b338e793"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/11490 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b070c93853ca4d8a9c71061a59b8fe5c"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"!pip install git\n!git clone https://github.com/osamakhaled123/Basic-Transformer-Model\n!cd '/content/Basic-Transformer-Model'\n%cd Basic-Transformer-Model/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T13:00:54.476178Z","iopub.execute_input":"2025-06-25T13:00:54.477069Z","iopub.status.idle":"2025-06-25T13:00:57.035158Z","shell.execute_reply.started":"2025-06-25T13:00:54.477041Z","shell.execute_reply":"2025-06-25T13:00:57.033968Z"},"id":"sfHHmRecm94F","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5bd44b0d-ab65-4e65-d0ea-d5691bd5e538"},"outputs":[{"name":"stdout","text":"\u001b[31mERROR: Could not find a version that satisfies the requirement git (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for git\u001b[0m\u001b[31m\n\u001b[0mCloning into 'Basic-Transformer-Model'...\nremote: Enumerating objects: 67, done.\u001b[K\nremote: Counting objects: 100% (67/67), done.\u001b[K\nremote: Compressing objects: 100% (53/53), done.\u001b[K\nremote: Total 67 (delta 31), reused 48 (delta 14), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (67/67), 41.52 KiB | 6.92 MiB/s, done.\nResolving deltas: 100% (31/31), done.\n/bin/bash: line 1: cd: /content/Basic-Transformer-Model: No such file or directory\n/kaggle/working/Basic-Transformer-Model\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import Processing_Summarizing_Datasets_From_Scratch as pre","metadata":{"id":"9e_rDz418Oqg","trusted":true,"execution":{"iopub.status.busy":"2025-06-25T13:00:57.036971Z","iopub.execute_input":"2025-06-25T13:00:57.037304Z","iopub.status.idle":"2025-06-25T13:00:57.044335Z","shell.execute_reply.started":"2025-06-25T13:00:57.037278Z","shell.execute_reply":"2025-06-25T13:00:57.043750Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"articles = np.array(dataset['train'][:14000]['article'])\nsummaries = np.array(dataset['train'][:14000]['highlights'])\ntexts = {'articles':articles,\n         'summaries':summaries}\nmax_input_len = 1000\nmax_target_len = 85","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T13:01:04.462621Z","iopub.execute_input":"2025-06-25T13:01:04.462886Z","iopub.status.idle":"2025-06-25T13:01:05.172774Z","shell.execute_reply.started":"2025-06-25T13:01:04.462862Z","shell.execute_reply":"2025-06-25T13:01:05.171965Z"},"id":"a49AoYcUm94G"},"outputs":[],"execution_count":5},{"cell_type":"code","source":"text_train, train_data, train_target, vocab = pre.preprocessing(texts, max_input_len, max_target_len, {})","metadata":{"trusted":true,"id":"UmjOww7Gm94H","execution":{"iopub.status.busy":"2025-06-25T13:01:05.174010Z","iopub.execute_input":"2025-06-25T13:01:05.174259Z","iopub.status.idle":"2025-06-25T13:01:34.595254Z","shell.execute_reply.started":"2025-06-25T13:01:05.174236Z","shell.execute_reply":"2025-06-25T13:01:34.594678Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"text_train.shape, train_data.shape, train_target.shape, len(vocab)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CbOcRtdfUqVk","outputId":"9f94c265-63f8-499d-defa-81b2fb000c32","trusted":true,"execution":{"iopub.status.busy":"2025-06-25T13:01:37.773355Z","iopub.execute_input":"2025-06-25T13:01:37.774057Z","iopub.status.idle":"2025-06-25T13:01:37.779259Z","shell.execute_reply.started":"2025-06-25T13:01:37.774034Z","shell.execute_reply":"2025-06-25T13:01:37.778677Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"((27932,), torch.Size([13966, 1000]), torch.Size([13966, 85]), 113285)"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"train_set, val_set, test_set = pre.splitting_and_batching(input_data=train_data, target_data=train_target,\n                                                          split_frac=0.9, batch_size=32)","metadata":{"id":"NbXj1RXVtkVf","trusted":true,"execution":{"iopub.status.busy":"2025-06-25T13:01:40.138585Z","iopub.execute_input":"2025-06-25T13:01:40.138864Z","iopub.status.idle":"2025-06-25T13:01:40.152444Z","shell.execute_reply.started":"2025-06-25T13:01:40.138846Z","shell.execute_reply":"2025-06-25T13:01:40.151720Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"#Positional Encoding","metadata":{"id":"rtLQxPhbAT8a"}},{"cell_type":"code","source":"class positional_encoding(nn.Module):\n    def __init__(self, max_length, emb_dim):\n        super(positional_encoding, self).__init__()\n\n        self.pos_enc = torch.zeros(size=(max_length, emb_dim))\n        self.pos=torch.arange(1, max_length+1, dtype=torch.float32).unsqueeze(1).repeat(1,emb_dim)\n        self.equation = torch.pow(max_length, (2*torch.arange(emb_dim))/emb_dim).tile(max_length,1)\n\n    def forward(self):\n        self.pos_enc[:,0::2] = torch.sin(self.pos[:,0::2] / self.equation[:,0::2])\n        self.pos_enc[:,1::2] = torch.cos(self.pos[:,1::2] / self.equation[:,1::2])\n\n        pos_vector = self.pos_enc.unsqueeze(0)\n       \n        return pos_vector","metadata":{"id":"ewhGuyIl2nyg","trusted":true,"execution":{"iopub.status.busy":"2025-06-25T13:01:44.510317Z","iopub.execute_input":"2025-06-25T13:01:44.510954Z","iopub.status.idle":"2025-06-25T13:01:44.516333Z","shell.execute_reply.started":"2025-06-25T13:01:44.510931Z","shell.execute_reply":"2025-06-25T13:01:44.515673Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"#Scaled dot-product Attention","metadata":{"id":"5DxBWqjCKU5G"}},{"cell_type":"code","source":"class scaled_dot_product_attention(nn.Module):\n    def __init__(self, emb_dim, causal = False, dropout = 0.1): #size=(batch, max_len, emb_dim)\n        super(scaled_dot_product_attention, self).__init__()\n\n        self.Q_linear = nn.Linear(emb_dim, emb_dim, dtype=torch.float32)\n        self.K_linear = nn.Linear(emb_dim, emb_dim, dtype=torch.float32)\n        self.V_linear = nn.Linear(emb_dim, emb_dim, dtype=torch.float32)\n        self.dropout = nn.Dropout(dropout)\n        self.causal = causal\n        self.softmax = nn.Softmax(dim=-1)\n\n    def forward(self, Q, K, V, attention_mask):\n        Q = self.Q_linear(Q)\n        Q = self.dropout(Q)\n\n        K = self.K_linear(K)\n        K = self.dropout(K)\n\n        V = self.V_linear(V)\n        V = self.dropout(V)\n\n        scores = torch.matmul(Q, torch.transpose(K,-1,-2))\n        dk = torch.sqrt(torch.tensor(K.size(-1)))\n        scores /= dk\n        #print(f\"Scores size is {scores.shape} with Q size {Q.shape} and K size {K.shape}\",end='\\n\\n')\n        #print(f\"attention mask shape is {attention_mask.shape}\", end='\\n\\n')\n        scores = scores.masked_fill(attention_mask == 0, float(-1e10))\n\n        if self.causal:\n            mask = torch.ones(size=(scores.size(-1), scores.size(-2))).to(scores.device)\n            mask = torch.triu(input=mask, diagonal=1)\n            mask = mask.masked_fill(mask == 1, float(-1e10))\n            scores += mask\n\n        attention_weights = self.softmax(scores)\n        results = torch.matmul(attention_weights, V)\n\n        return results","metadata":{"id":"kLq20yYdJ5T1","trusted":true,"execution":{"iopub.status.busy":"2025-06-25T13:01:45.046735Z","iopub.execute_input":"2025-06-25T13:01:45.047426Z","iopub.status.idle":"2025-06-25T13:01:45.054269Z","shell.execute_reply.started":"2025-06-25T13:01:45.047405Z","shell.execute_reply":"2025-06-25T13:01:45.053592Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"#Multi-head Attention","metadata":{"id":"cV1MpQMFoy6C"}},{"cell_type":"code","source":"class multihead_attention(nn.Module):\n    def __init__(self, num_heads, emb_dim, causal=False, dropout=0.1):\n        super(multihead_attention, self).__init__()\n\n        self.input_batch = int(emb_dim // num_heads)\n        self.linear_projection = nn.Linear(emb_dim, emb_dim, dtype=torch.float32)\n        self.dropout = nn.Dropout(dropout)\n        self.heads = nn.ModuleList([\n            scaled_dot_product_attention(self.input_batch, causal, dropout)\n            for head in range(num_heads)])\n\n    def forward(self, Q, K, V, attention_mask):\n        outputs = []\n        range = 0\n        for head in self.heads:\n            outputs.append(head(Q[:,:,range:range+self.input_batch],\n                                K[:,:,range:range+self.input_batch],\n                                V[:,:,range:range+self.input_batch],\n                                attention_mask))\n            range += self.input_batch\n\n        concatenated_heads_outputs = torch.cat(outputs, dim=-1)\n        linear_projection = self.linear_projection(concatenated_heads_outputs)\n        linear_projection = self.dropout(linear_projection)\n\n        return linear_projection","metadata":{"id":"Q1jtEWmkoaw8","trusted":true,"execution":{"iopub.status.busy":"2025-06-25T13:01:45.573083Z","iopub.execute_input":"2025-06-25T13:01:45.573363Z","iopub.status.idle":"2025-06-25T13:01:45.579923Z","shell.execute_reply.started":"2025-06-25T13:01:45.573345Z","shell.execute_reply":"2025-06-25T13:01:45.579278Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"#Transformer Encoder-Decoder","metadata":{"id":"hZC_-q3XZPyl"}},{"cell_type":"code","source":"class transformer_encoder_decoder(nn.Module):\n    def __init__(self, num_heads, emb_dim, dff, dropout=0.1):\n        super(transformer_encoder_decoder, self).__init__()\n        self.multi_head_attention = multihead_attention(num_heads, emb_dim,\n                                                        dropout=dropout)\n        self.layer_normalization_1 = nn.LayerNorm(emb_dim, dtype=torch.float32)\n        self.layer_normalization_2 = nn.LayerNorm(emb_dim, dtype=torch.float32)\n        self.RelU_layer = nn.Linear(emb_dim, dff, dtype=torch.float32)\n        self.RelU = nn.ReLU()\n        self.Linear_layer = nn.Linear(dff, emb_dim, dtype=torch.float32)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, Q, K, V, attention_mask):\n        layer = self.multi_head_attention(Q, K, V, attention_mask)\n        layer += Q\n        normalized = self.layer_normalization_1(layer)\n        #The dimensionality of input and output is dmodel = 512,\n        #and the inner-layer has dimensionality dff = 2048\n        layer = self.RelU_layer(normalized)\n        layer = self.RelU(layer)\n        layer = self.dropout(layer)\n        layer = self.Linear_layer(layer)\n        layer = self.dropout(layer)\n        layer += normalized\n        output = self.layer_normalization_2(layer)\n\n        return output\n","metadata":{"id":"WAfrJizwZOu7","trusted":true,"execution":{"iopub.status.busy":"2025-06-25T13:01:46.270082Z","iopub.execute_input":"2025-06-25T13:01:46.270574Z","iopub.status.idle":"2025-06-25T13:01:46.276562Z","shell.execute_reply.started":"2025-06-25T13:01:46.270551Z","shell.execute_reply":"2025-06-25T13:01:46.275955Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"#Transformer","metadata":{"id":"SWG6TEkSBcCD"}},{"cell_type":"code","source":"class Transformer(nn.Module):\n    def __init__(self, vocab, max_input_length, max_target_length,\n                 emb_dim, dff, num_heads, num_encoder_blocks, num_decoder_blocks,\n                 dropout):\n        super(Transformer, self).__init__()\n        self.vocab = vocab\n        self.max_input_length = max_input_length\n        self.max_target_length = max_target_length\n        self.emb_dim = emb_dim\n        self.num_heads = num_heads\n        self.num_encoder_blocks = num_encoder_blocks\n        self.num_decoder_blocks = num_decoder_blocks\n        self.dff = dff\n        self.Dropout = nn.Dropout(dropout)\n\n        self.embedding = nn.Embedding(len(vocab), emb_dim, padding_idx=vocab['pad'])\n        self.positional_encoding_encoder = positional_encoding(max_input_length-1, emb_dim)\n        self.positional_encoding_decoder = positional_encoding(max_target_length-1, emb_dim)\n\n        self.encoder_blocks = nn.ModuleList([transformer_encoder_decoder(num_heads,\n        emb_dim, dff, dropout) for _ in range(num_encoder_blocks)])\n\n        self.decoder_blocks = nn.ModuleList([transformer_encoder_decoder(num_heads,\n        emb_dim, dff, dropout) for _ in range(num_decoder_blocks)])\n\n        self.masked_attention = multihead_attention(num_heads, emb_dim, True, dropout)\n        self.layer_normalization = nn.LayerNorm(emb_dim, dtype=torch.float32)\n\n    def forward(self, batch, target):\n        #Encoder Part\n        training_data = self.embedding(batch)\n        #Positional Encoding masking for training data\n        positional_mask_batch = (batch != self.vocab['<pad>']).unsqueeze(-1).float()\n        training_data *= positional_mask_batch\n        \n        training_data += self.positional_encoding_encoder().to(training_data.device) * positional_mask_batch\n        #Attention masking for training data\n        attention_mask_batch = (batch != self.vocab['<pad>']).unsqueeze(-1).float()\n\n        encoder_output = self.encoder_decoder(training_data,\n                                              training_data,\n                                              training_data,\n                                               self.encoder_blocks,\n                                               attention_mask_batch)\n        K, V = encoder_output, encoder_output\n\n        #Decoder Part\n        target_data = self.embedding(target)\n        #Positional Encoding masking for target data\n        positional_mask_target = (target != self.vocab['<pad>']).unsqueeze(-1).float()\n        target_data *= positional_mask_target\n        target_data += self.positional_encoding_decoder().to(target_data.device) * positional_mask_target\n        #Attention masking for target data\n        attention_mask_target = (target != self.vocab['<pad>']).unsqueeze(-1).float()\n\n\n        masked_attention_output = self.masked_attention(target_data,\n                                                        target_data,\n                                                        target_data,\n                                                        attention_mask_target)\n        out = masked_attention_output + target_data\n        Q = self.layer_normalization(out)\n\n        decoder_output = self.encoder_decoder(Q, K, V, self.decoder_blocks,\n                                              attention_mask_target)\n\n        pre_softmax = torch.nn.functional.linear(decoder_output, self.embedding.weight)\n        pre_softmax = self.Dropout(pre_softmax)\n\n        return pre_softmax\n    #Encoder-Decoder Blocks\n    def encoder_decoder(self, Q, K, V, blocks, attention_mask):\n        for block in blocks:\n            result = block(Q, K, V, attention_mask)\n            Q, K, V = result, result, result\n\n        return result","metadata":{"id":"kzhUZTLGBbUV","trusted":true,"execution":{"iopub.status.busy":"2025-06-25T13:01:47.404201Z","iopub.execute_input":"2025-06-25T13:01:47.404946Z","iopub.status.idle":"2025-06-25T13:01:47.415506Z","shell.execute_reply.started":"2025-06-25T13:01:47.404921Z","shell.execute_reply":"2025-06-25T13:01:47.414811Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"#Training Process","metadata":{"id":"jWATl1Z4MK9t"}},{"cell_type":"markdown","source":"#Positional Encoding and Attention MASKING\n#SOS and EOS Token Shifting","metadata":{"id":"baOhsKMps0Rm"}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nmodel = Transformer(\n    vocab=vocab,\n    max_input_length=max_input_len,\n    max_target_length=max_target_len,\n    emb_dim=256,\n    dff=1024,\n    num_heads=4,\n    num_encoder_blocks=4,\n    num_decoder_blocks=4,\n    dropout=0.1\n).to(device)","metadata":{"id":"32VkNx-9PQIp","trusted":true,"execution":{"iopub.status.busy":"2025-06-25T13:01:50.383774Z","iopub.execute_input":"2025-06-25T13:01:50.384072Z","iopub.status.idle":"2025-06-25T13:01:51.047303Z","shell.execute_reply.started":"2025-06-25T13:01:50.384052Z","shell.execute_reply":"2025-06-25T13:01:51.046509Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"","metadata":{"id":"G0hxr5bUCVd-","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train(model, train_set, val_set, epochs, l, vocab, device):\n    criterion = nn.CrossEntropyLoss(ignore_index=vocab['<pad>'])\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n    train_losses = []\n    val_losses = []\n\n    for epoch in range(epochs):\n        train_accuracy = 0\n        val_accuracy = 0.0\n        training_loss = 0.0\n        validation_loss = 0.0\n\n        model.train()\n        train_loop = tqdm(train_set, desc=f\"Train Epoch {epoch+1}\", leave=False)\n        \n        for train_batch, target_train_batch in train_loop:\n            optimizer.zero_grad()\n            \n            train_batch, target_train_batch = train_batch.to(device), target_train_batch.to(device)\n\n            predicted_output = model(train_batch[:,1:], target_train_batch[:,:-1])\n\n            logits = predicted_output.contiguous().view(-1, predicted_output.size(-1))\n            targets = target_train_batch[:,1:].contiguous().view(-1)\n            \n            loss = criterion(logits, targets)\n            loss.backward()\n            optimizer.step()\n\n            training_loss += loss.item()\n            #_, pred_class = torch.max(predicted_output, 1)\n            #equals = pred_class == target_train_batch.view(*pred_class.shape)\n            #train_accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n\n        train_losses.append(training_loss/len(train_set))\n        print(f\"Epoch {epoch+1} accumelated Training batches loss is:\\t\\t {training_loss/len(train_set)}\")\n        #print(f\"Epoch {epoch+1} accuracy on Training batches is:\\t\\t {train_accuracy / len(train_set)}\")\n\n\n        model.eval()\n        val_loop = tqdm(val_set, desc=f\"Validation Epoch {epoch+1}\", leave=False)\n\n        with torch.no_grad():\n            for valid_batch, target_valid_batch in val_loop:\n                \n                valid_batch, target_valid_batch = valid_batch.to(device), target_valid_batch.to(device)\n                predicted_output = model(valid_batch[:,1:], target_valid_batch[:,:-1])\n                \n                logits = predicted_output.contiguous().view(-1, predicted_output.size(-1))\n                targets = target_valid_batch[:,1:].contiguous().view(-1)\n                \n                loss = criterion(logits, targets)\n                validation_loss += loss.item()\n                #_, pred_class=torch.max(predicted_output, 1)\n                #equals = pred_class == target_valid_batch.view(*pred_class.shape)\n                #val_accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n    \n        val_losses.append(validation_loss/len(val_set))\n        print(f\"Epoch {epoch+1} accumelated validation batches loss is:\\t\\t {validation_loss/len(val_set)}\")\n        #print(f\"Epoch {epoch+1} accuracy on validation batches is:\\t\\t {val_accuracy / len(val_set)}\")\n\n    return train_losses, val_losses\n","metadata":{"id":"zcOnFvBjeQmB","trusted":true,"execution":{"iopub.status.busy":"2025-06-25T13:02:05.866229Z","iopub.execute_input":"2025-06-25T13:02:05.866976Z","iopub.status.idle":"2025-06-25T13:02:05.875354Z","shell.execute_reply.started":"2025-06-25T13:02:05.866952Z","shell.execute_reply":"2025-06-25T13:02:05.874773Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"train_losses = val_losses = train(model, train_set, val_set, 3, 0.001, vocab, device)","metadata":{"id":"F_sQ8tPgJLTB","trusted":true,"execution":{"iopub.status.busy":"2025-06-25T13:06:37.442551Z","iopub.execute_input":"2025-06-25T13:06:37.442999Z","iopub.status.idle":"2025-06-25T13:15:48.397484Z","shell.execute_reply.started":"2025-06-25T13:06:37.442981Z","shell.execute_reply":"2025-06-25T13:15:48.396699Z"}},"outputs":[{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1 accumelated Training batches loss is:\t\t 28.005582362944235\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1 accumelated validation batches loss is:\t\t 19.310763532465156\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2 accumelated Training batches loss is:\t\t 20.007177241279273\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2 accumelated validation batches loss is:\t\t 14.266323349692605\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3 accumelated Training batches loss is:\t\t 15.12140446340158\n","output_type":"stream"},{"name":"stderr","text":"                                                                   ","output_type":"stream"},{"name":"stdout","text":"Epoch 3 accumelated validation batches loss is:\t\t 11.38800608028065\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"torch.save(model.state_dict(), 'transformer_weight.pt')","metadata":{"id":"tNQD9yVzshK2","trusted":true,"execution":{"iopub.status.busy":"2025-06-25T13:26:49.209188Z","iopub.execute_input":"2025-06-25T13:26:49.209558Z","iopub.status.idle":"2025-06-25T13:26:49.504899Z","shell.execute_reply.started":"2025-06-25T13:26:49.209535Z","shell.execute_reply":"2025-06-25T13:26:49.504268Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"#Testing Codes","metadata":{"id":"tsVUeDMLsinw"}},{"cell_type":"code","source":"iterator = iter(train_set)","metadata":{"id":"vHra3mrHChZL"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"batch, target = next(iterator)","metadata":{"id":"LCzFFQ6XCn-t"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"batch.shape, target.shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iGzJJqd5Cr-L","outputId":"f9a29cd0-60be-46d7-ff3f-c588ddf5fe74"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([32, 1000]), torch.Size([32, 85]))"]},"metadata":{},"execution_count":15}],"execution_count":null},{"cell_type":"code","source":"target[0]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RExln0wECtxL","outputId":"ea2ea303-d4bc-4ad3-b438-17118751183f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([     1,  38560,  54023,  30743, 103207,  92033,  71293,  96132, 100583,\n","         88557,  18240,  13712,  22970,  60995,  66642,  82970,  18240,  62287,\n","         82394,  42604,   9095,  56881,  12762,  33954,  20988, 107106,   4712,\n","         10009,  16332, 107283,  54023,  97259,  90458,  38045,  11170, 101889,\n","         94238,  85881,      2,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0])"]},"metadata":{},"execution_count":16}],"execution_count":null},{"cell_type":"code","source":"emb = nn.Embedding(len(vocab), 256)","metadata":{"id":"yZ5Tx-n36ABJ"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"target_data = emb(target)","metadata":{"id":"65btS3Z16E-4"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"target_data.shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uNSL8kjB6MPX","outputId":"d2a91392-7bcc-4b20-e5e2-c7cb6cc2af8f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([32, 85, 256])"]},"metadata":{},"execution_count":50}],"execution_count":null},{"cell_type":"code","source":"attention_mask = (target != 0)#.unsqueeze(1)","metadata":{"id":"hiC7oWu-6TxT"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"attention_mask.shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ICejb1CwwPXj","outputId":"8863783e-b9cf-4a1c-d9cd-86fcf8352667"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([32, 85])"]},"metadata":{},"execution_count":22}],"execution_count":null},{"cell_type":"code","source":"attention_mask[0]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xQN1cRuxwQfQ","outputId":"906a5d38-0e77-4e5e-b586-960950d843fc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n","         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n","         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n","         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n","        False, False, False, False, False, False, False, False, False, False,\n","        False, False, False, False, False, False, False, False, False, False,\n","        False, False, False, False, False, False, False, False, False, False,\n","        False, False, False, False, False, False, False, False, False, False,\n","        False, False, False, False, False])"]},"metadata":{},"execution_count":23}],"execution_count":null},{"cell_type":"code","source":"r = target[0]","metadata":{"id":"yaebZlrIwd4N"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"r","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v_YsfK-S3YiQ","outputId":"560fb92b-7fed-405a-be5a-14b18b8133d5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([     1,  38560,  54023,  30743, 103207,  92033,  71293,  96132, 100583,\n","         88557,  18240,  13712,  22970,  60995,  66642,  82970,  18240,  62287,\n","         82394,  42604,   9095,  56881,  12762,  33954,  20988, 107106,   4712,\n","         10009,  16332, 107283,  54023,  97259,  90458,  38045,  11170, 101889,\n","         94238,  85881,      2,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0])"]},"metadata":{},"execution_count":37}],"execution_count":null},{"cell_type":"code","source":"y = r * torch.tensor([1])","metadata":{"id":"Fgu-FTu93DAk"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.tensor([1]).shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TThVO1tr3FhL","outputId":"b3622cba-0de9-4783-9b45-9251847d2d36"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1])"]},"metadata":{},"execution_count":39}],"execution_count":null},{"cell_type":"code","source":"y","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UYnobMe23Rb6","outputId":"d4f487fa-a1e9-41ad-9475-9e5720555c77"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([     1,  38560,  54023,  30743, 103207,  92033,  71293,  96132, 100583,\n","         88557,  18240,  13712,  22970,  60995,  66642,  82970,  18240,  62287,\n","         82394,  42604,   9095,  56881,  12762,  33954,  20988, 107106,   4712,\n","         10009,  16332, 107283,  54023,  97259,  90458,  38045,  11170, 101889,\n","         94238,  85881,      2,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0])"]},"metadata":{},"execution_count":40}],"execution_count":null},{"cell_type":"code","source":"r = r.masked_fill(r==0 , 8)","metadata":{"id":"nTAIEbcX3Tds"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"r","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8DpZoywG-6y5","outputId":"fc36ecaf-208c-44fa-c7b0-b729d805a554"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([     1,  38560,  54023,  30743, 103207,  92033,  71293,  96132, 100583,\n","         88557,  18240,  13712,  22970,  60995,  66642,  82970,  18240,  62287,\n","         82394,  42604,   9095,  56881,  12762,  33954,  20988, 107106,   4712,\n","         10009,  16332, 107283,  54023,  97259,  90458,  38045,  11170, 101889,\n","         94238,  85881,      2,      8,      8,      8,      8,      8,      8,\n","             8,      8,      8,      8,      8,      8,      8,      8,      8,\n","             8,      8,      8,      8,      8,      8,      8,      8,      8,\n","             8,      8,      8,      8,      8,      8,      8,      8,      8,\n","             8,      8,      8,      8,      8,      8,      8,      8,      8,\n","             8,      8,      8,      8])"]},"metadata":{},"execution_count":45}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"tsJjuwFb_ORV"},"outputs":[],"execution_count":null}]}