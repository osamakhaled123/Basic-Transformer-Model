{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 12025869,
          "sourceType": "datasetVersion",
          "datasetId": 7566230
        },
        {
          "sourceId": 243059908,
          "sourceType": "kernelVersion"
        },
        {
          "sourceId": 421259,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": true,
          "modelInstanceId": 343315,
          "modelId": 364597
        }
      ],
      "dockerImageVersionId": 31040,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-01T19:21:02.54194Z",
          "iopub.execute_input": "2025-06-01T19:21:02.54238Z",
          "iopub.status.idle": "2025-06-01T19:21:12.077292Z",
          "shell.execute_reply.started": "2025-06-01T19:21:02.542301Z",
          "shell.execute_reply": "2025-06-01T19:21:12.076114Z"
        },
        "id": "kJt1cuRPm93-"
      },
      "outputs": [],
      "execution_count": 29
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade datasets\n",
        "dataset = load_dataset(\"cnn_dailymail\",\"3.0.0\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-01T19:21:12.079336Z",
          "iopub.execute_input": "2025-06-01T19:21:12.080151Z",
          "iopub.status.idle": "2025-06-01T19:21:34.441452Z",
          "shell.execute_reply.started": "2025-06-01T19:21:12.080116Z",
          "shell.execute_reply": "2025-06-01T19:21:34.440296Z"
        },
        "id": "PJnUKhUvm93_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "352d9285-f547-420f-d474-737f1276cf6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.33.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.6.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "execution_count": 30
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git\n",
        "!git clone https://github.com/osamakhaled123/Basic-Transformer-Model\n",
        "!cd '/content/Basic-Transformer-Model'\n",
        "%cd Basic-Transformer-Model/"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-01T18:28:37.561581Z",
          "iopub.execute_input": "2025-06-01T18:28:37.56194Z",
          "iopub.status.idle": "2025-06-01T18:28:37.570113Z",
          "shell.execute_reply.started": "2025-06-01T18:28:37.561913Z",
          "shell.execute_reply": "2025-06-01T18:28:37.568614Z"
        },
        "id": "sfHHmRecm94F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bd44b0d-ab65-4e65-d0ea-d5691bd5e538"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement git (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for git\u001b[0m\u001b[31m\n",
            "\u001b[0mCloning into 'Basic-Transformer-Model'...\n",
            "remote: Enumerating objects: 64, done.\u001b[K\n",
            "remote: Counting objects: 100% (64/64), done.\u001b[K\n",
            "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
            "remote: Total 64 (delta 30), reused 46 (delta 14), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (64/64), 34.82 KiB | 2.68 MiB/s, done.\n",
            "Resolving deltas: 100% (30/30), done.\n",
            "/content/Basic-Transformer-Model/Basic-Transformer-Model\n"
          ]
        }
      ],
      "execution_count": 31
    },
    {
      "cell_type": "code",
      "source": [
        "import Processing_Summarizing_Datasets_From_Scratch as pre"
      ],
      "metadata": {
        "id": "9e_rDz418Oqg"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "articles = np.array(dataset['train'][:14000]['article'])\n",
        "summaries = np.array(dataset['train'][:14000]['highlights'])\n",
        "texts = {'articles':articles,\n",
        "         'summaries':summaries}\n",
        "max_input_len = 1000\n",
        "max_target_len = 85"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-01T10:20:13.802054Z",
          "iopub.execute_input": "2025-06-01T10:20:13.80228Z",
          "iopub.status.idle": "2025-06-01T10:20:14.641989Z",
          "shell.execute_reply.started": "2025-06-01T10:20:13.802262Z",
          "shell.execute_reply": "2025-06-01T10:20:14.64094Z"
        },
        "id": "a49AoYcUm94G"
      },
      "outputs": [],
      "execution_count": 33
    },
    {
      "cell_type": "code",
      "source": [
        "text_train, train_data, train_target, vocab = pre.preprocessing(texts, max_input_len, max_target_len, {})"
      ],
      "metadata": {
        "trusted": true,
        "id": "UmjOww7Gm94H"
      },
      "outputs": [],
      "execution_count": 34
    },
    {
      "cell_type": "code",
      "source": [
        "text_train.shape, train_data.shape, train_target.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbOcRtdfUqVk",
        "outputId": "9f94c265-63f8-499d-defa-81b2fb000c32"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((27932,), torch.Size([13966, 1000]), torch.Size([13966, 85]))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set, val_set, test_set = pre.splitting_and_batching(input_data=train_data, target_data=train_target,\n",
        "                                                          split_frac=0.9, batch_size=32)"
      ],
      "metadata": {
        "id": "NbXj1RXVtkVf"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Positional Encoding"
      ],
      "metadata": {
        "id": "rtLQxPhbAT8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class positional_encoding(nn.Module):\n",
        "    def __init__(self, max_length, emb_dim):\n",
        "        super(positional_encoding, self).__init__()\n",
        "\n",
        "        self.pos_enc = torch.zeros(size=(max_length, emb_dim))\n",
        "        self.pos=torch.arange(1, max_length+1, dtype=torch.float32).unsqueeze(1).repeat(1,emb_dim)\n",
        "        self.equation = torch.pow(max_length, (2*torch.arange(emb_dim))/emb_dim).tile(max_length,1)\n",
        "\n",
        "    def forward(self):\n",
        "        self.pos_enc[:,0::2] = torch.sin(self.pos[:,0::2] / self.equation[:,0::2])\n",
        "        self.pos_enc[:,1::2] = torch.cos(self.pos[:,1::2] / self.equation[:,1::2])\n",
        "\n",
        "        self.pos_enc = self.pos_enc.unsqueeze(0)\n",
        "        return self.pos_enc"
      ],
      "metadata": {
        "id": "ewhGuyIl2nyg"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Scaled dot-product Attention"
      ],
      "metadata": {
        "id": "5DxBWqjCKU5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class scaled_dot_product_attention(nn.Module):\n",
        "    def __init__(self, emb_dim, causal = False, dropout = 0.1): #size=(batch, max_len, emb_dim)\n",
        "        super(scaled_dot_product_attention, self).__init__()\n",
        "\n",
        "        self.Q_linear = nn.Linear(emb_dim, emb_dim, dtype=torch.float32)\n",
        "        self.K_linear = nn.Linear(emb_dim, emb_dim, dtype=torch.float32)\n",
        "        self.V_linear = nn.Linear(emb_dim, emb_dim, dtype=torch.float32)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.causal = causal\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, Q, K, V, attention_mask):\n",
        "        Q = self.Q_linear(Q)\n",
        "        Q = self.dropout(Q)\n",
        "\n",
        "        K = self.K_linear(K)\n",
        "        K = self.dropout(K)\n",
        "\n",
        "        V = self.V_linear(V)\n",
        "        V = self.dropout(V)\n",
        "\n",
        "        scores = torch.matmul(Q, torch.transpose(K,-1,-2))\n",
        "        dk = torch.sqrt(torch.tensor(K.size(-1)))\n",
        "        scores /= dk\n",
        "        scores = scores.masked_fill(attention_mask == 0, float(-1e10))\n",
        "\n",
        "        if self.causal:\n",
        "            mask = torch.ones(size=(scores.size(-1), scores.size(-2)))\n",
        "            mask = torch.triu(input=mask, diagonal=1)\n",
        "            mask = mask.masked_fill(mask == 1, float(-1e10))\n",
        "            scores += mask\n",
        "\n",
        "        attention_weights = self.softmax(scores)\n",
        "        results = torch.matmul(attention_weights, V)\n",
        "\n",
        "        return results"
      ],
      "metadata": {
        "id": "kLq20yYdJ5T1"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Multi-head Attention"
      ],
      "metadata": {
        "id": "cV1MpQMFoy6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class multihead_attention(nn.Module):\n",
        "    def __init__(self, num_heads, emb_dim, causal=False, dropout=0.1):\n",
        "        super(multihead_attention, self).__init__()\n",
        "\n",
        "        self.input_batch = int(emb_dim // num_heads)\n",
        "        self.linear_projection = nn.Linear(emb_dim, emb_dim, dtype=torch.float32)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.heads = nn.ModuleList([\n",
        "            scaled_dot_product_attention(self.input_batch, causal, dropout)\n",
        "            for head in range(num_heads)])\n",
        "\n",
        "    def forward(self, Q, K, V, attention_mask):\n",
        "        outputs = []\n",
        "        range = 0\n",
        "        for head in self.heads:\n",
        "            outputs.append(head(Q[:,:,range:range+self.input_batch],\n",
        "                                K[:,:,range:range+self.input_batch],\n",
        "                                V[:,:,range:range+self.input_batch],\n",
        "                                attention_mask))\n",
        "            range += self.input_batch\n",
        "\n",
        "        concatenated_heads_outputs = torch.cat(outputs, dim=-1)\n",
        "        linear_projection = self.linear_projection(concatenated_heads_outputs)\n",
        "        linear_projection = self.dropout(linear_projection)\n",
        "\n",
        "        return linear_projection"
      ],
      "metadata": {
        "id": "Q1jtEWmkoaw8"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Transformer Encoder-Decoder"
      ],
      "metadata": {
        "id": "hZC_-q3XZPyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class transformer_encoder_decoder(nn.Module):\n",
        "    def __init__(self, num_heads, emb_dim, dff, dropout=0.1):\n",
        "        super(transformer_encoder_decoder, self).__init__()\n",
        "        self.multi_head_attention = multihead_attention(num_heads, emb_dim,\n",
        "                                                        dropout=dropout)\n",
        "        self.layer_normalization_1 = nn.LayerNorm(emb_dim, dtype=torch.float32)\n",
        "        self.layer_normalization_2 = nn.LayerNorm(emb_dim, dtype=torch.float32)\n",
        "        self.RelU_layer = nn.Linear(emb_dim, dff, dtype=torch.float32)\n",
        "        self.RelU = nn.ReLU()\n",
        "        self.Linear_layer = nn.Linear(dff, emb_dim, dtype=torch.float32)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, Q, K, V, attention_mask):\n",
        "        layer = self.multi_head_attention(Q, K, V, attention_mask)\n",
        "        layer += Q\n",
        "        normalized = self.layer_normalization_1(layer)\n",
        "        #The dimensionality of input and output is dmodel = 512,\n",
        "        #and the inner-layer has dimensionality dff = 2048\n",
        "        layer = self.RelU_layer(normalized)\n",
        "        layer = self.RelU(layer)\n",
        "        layer = self.dropout(layer)\n",
        "        layer = self.Linear_layer(layer)\n",
        "        layer = self.dropout(layer)\n",
        "        layer += normalized\n",
        "        output = self.layer_normalization_2(layer)\n",
        "\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "WAfrJizwZOu7"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Transformer"
      ],
      "metadata": {
        "id": "SWG6TEkSBcCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, vocab, max_input_length, max_target_length,\n",
        "                 emb_dim, dff, num_heads, num_encoder_blocks, num_decoder_blocks,\n",
        "                 dropout):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.vocab = vocab\n",
        "        self.max_input_length = max_input_length\n",
        "        self.max_target_length = max_target_length\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.num_encoder_blocks = num_encoder_blocks\n",
        "        self.num_decoder_blocks = num_decoder_blocks\n",
        "        self.dff = dff\n",
        "        self.Dropout = nn.Dropout(dropout)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "        self.embedding = nn.Embedding(len(vocab), emb_dim, padding_idx=vocab['pad'])\n",
        "        self.positional_encoding_encoder = positional_encoding(max_input_length-1, emb_dim)\n",
        "        self.positional_encoding_decoder = positional_encoding(max_target_length-1, emb_dim)\n",
        "\n",
        "        self.encoder_blocks = nn.ModuleList([transformer_encoder_decoder(num_heads,\n",
        "        emb_dim, dff, dropout) for _ in range(num_encoder_blocks)])\n",
        "\n",
        "        self.decoder_blocks = nn.ModuleList([transformer_encoder_decoder(num_heads,\n",
        "        emb_dim, dff, dropout) for _ in range(num_decoder_blocks)])\n",
        "\n",
        "        self.masked_attention = multihead_attention(num_heads, emb_dim, True, dropout)\n",
        "        self.layer_normalization = nn.LayerNorm(emb_dim, dtype=torch.float32)\n",
        "\n",
        "    def forward(self, batch, target):\n",
        "        #Encoder Part\n",
        "        training_data = self.embedding(batch)\n",
        "        #Positional Encoding masking for training data\n",
        "        positional_mask_batch = (batch != self.vocab['<pad>']).unsqueeze(-1).float()\n",
        "        training_data *= positional_mask_batch\n",
        "        training_data += self.positional_encoding_encoder() * positional_mask_batch\n",
        "        #Attention masking for training data\n",
        "        attention_mask_batch = (batch != self.vocab['<pad>']).unsqueeze(1).float()\n",
        "\n",
        "        encoder_output = self.encoder_decoder(training_data,\n",
        "                                              training_data,\n",
        "                                              training_data,\n",
        "                                               self.encoder_blocks,\n",
        "                                               attention_mask_batch)\n",
        "        K, V = encoder_output, encoder_output\n",
        "\n",
        "        #Decoder Part\n",
        "        target_data = self.embedding(target)\n",
        "        #Positional Encoding masking for target data\n",
        "        positional_mask_target = (target != self.vocab['<pad>']).unsqueeze(-1).float()\n",
        "        target_data *= positional_mask_target\n",
        "        target_data += self.positional_encoding_decoder() * positional_mask_target\n",
        "        #Attention masking for target data\n",
        "        attention_mask_target = (target != self.vocab['<pad>']).unsqueeze(1).float()\n",
        "\n",
        "\n",
        "        masked_attention_output = self.masked_attention(target_data,\n",
        "                                                        target_data,\n",
        "                                                        target_data,\n",
        "                                                        attention_mask_target)\n",
        "        out = masked_attention_output + target_data\n",
        "        Q = self.layer_normalization(out)\n",
        "\n",
        "        decoder_output = self.encoder_decoder(Q, K, V, self.decoder_blocks,\n",
        "                                              attention_mask_batch)\n",
        "\n",
        "        pre_softmax = torch.nn.functional.linear(decoder_output, self.embedding.weight)\n",
        "        pre_softmax = self.Dropout(pre_softmax)\n",
        "\n",
        "        return pre_softmax\n",
        "    #Encoder-Decoder Blocks\n",
        "    def encoder_decoder(self, Q, K, V, blocks, attention_mask):\n",
        "        for block in blocks:\n",
        "            result = block(Q, K, V, attention_mask)\n",
        "            Q, K, V = result, result, result\n",
        "\n",
        "        return result"
      ],
      "metadata": {
        "id": "kzhUZTLGBbUV"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training Process"
      ],
      "metadata": {
        "id": "jWATl1Z4MK9t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Positional Encoding and Attention MASKING\n",
        "#SOS and EOS Token Shifting"
      ],
      "metadata": {
        "id": "baOhsKMps0Rm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = Transformer(\n",
        "    vocab=vocab,\n",
        "    max_input_length=max_input_len,\n",
        "    max_target_length=max_target_len,\n",
        "    emb_dim=256,\n",
        "    dff=1024,\n",
        "    num_heads=4,\n",
        "    num_encoder_blocks=4,\n",
        "    num_decoder_blocks=4,\n",
        "    dropout=0.1\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "32VkNx-9PQIp"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G0hxr5bUCVd-"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_set, val_set, epochs=2, lr=0.005, device=None):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        train_accuracy = 0\n",
        "        val_accuracy = 0.0\n",
        "        training_loss = 0.0\n",
        "        validation_loss = 0.0\n",
        "\n",
        "        model.train()\n",
        "        for train_batch, target_train_batch in train_set:\n",
        "            optimizer.zero_grad()\n",
        "            if torch.cuda.is_available():\n",
        "                train_batch, target_train_batch = train_batch.cuda(), target_train_batch.cuda()\n",
        "\n",
        "            predicted_output = model(train_batch[:,1:], target_train_batch[:,:-1])\n",
        "            loss = criterion(predicted_output, target_train_batch[:,1:])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            training_loss += loss.item()\n",
        "            _, pred_class = torch.max(predicted_output, 1)\n",
        "            equals = pred_class == target_train_batch.view(*pred_class.shape)\n",
        "            train_accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "\n",
        "        train_losses.append(training_loss/len(train_set))\n",
        "        print(f\"Epoch {epoch+1} accumelated Training batches loss is:\\t\\t {training_loss/len(train_set)}\")\n",
        "        print(f\"Epoch {epoch+1} accuracy on Training batches is:\\t\\t {train_accuracy / len(train_set)}\")\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "        for valid_batch, target_valid_batch in val_set:\n",
        "            predicted_output = model(valid_batch[:,1:], target_valid_batch[:,:-1])\n",
        "            loss = criterion(predicted_output, target_valid_batch[:,1:])\n",
        "\n",
        "            validation_loss += loss.item()\n",
        "            _, pred_class=torch.max(predicted_output, 1)\n",
        "            equals = pred_class == target_valid_batch.view(*pred_class.shape)\n",
        "            val_accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "\n",
        "        val_losses.append(validation_loss/len(val_set))\n",
        "        print(f\"Epoch {epoch+1} accumelated validation batches loss is:\\t\\t {validation_loss/len(val_set)}\")\n",
        "        print(f\"Epoch {epoch+1} accuracy on validation batches is:\\t\\t {val_accuracy / len(val_set)}\")\n",
        "\n",
        "    return train_losses, val_losses\n"
      ],
      "metadata": {
        "id": "zcOnFvBjeQmB"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = val_losses = train(model, train_set, val_set, 1, 0.001, device)"
      ],
      "metadata": {
        "id": "F_sQ8tPgJLTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tNQD9yVzshK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing Codes"
      ],
      "metadata": {
        "id": "tsVUeDMLsinw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iterator = iter(train_set)"
      ],
      "metadata": {
        "id": "vHra3mrHChZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch, target = next(iterator)"
      ],
      "metadata": {
        "id": "LCzFFQ6XCn-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch.shape, target.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGzJJqd5Cr-L",
        "outputId": "f9a29cd0-60be-46d7-ff3f-c588ddf5fe74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 1000]), torch.Size([32, 85]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RExln0wECtxL",
        "outputId": "ea2ea303-d4bc-4ad3-b438-17118751183f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([     1,  38560,  54023,  30743, 103207,  92033,  71293,  96132, 100583,\n",
              "         88557,  18240,  13712,  22970,  60995,  66642,  82970,  18240,  62287,\n",
              "         82394,  42604,   9095,  56881,  12762,  33954,  20988, 107106,   4712,\n",
              "         10009,  16332, 107283,  54023,  97259,  90458,  38045,  11170, 101889,\n",
              "         94238,  85881,      2,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb = nn.Embedding(len(vocab), 256)"
      ],
      "metadata": {
        "id": "yZ5Tx-n36ABJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_data = emb(target)"
      ],
      "metadata": {
        "id": "65btS3Z16E-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNSL8kjB6MPX",
        "outputId": "d2a91392-7bcc-4b20-e5e2-c7cb6cc2af8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 85, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_mask = (target != 0)#.unsqueeze(1)"
      ],
      "metadata": {
        "id": "hiC7oWu-6TxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_mask.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICejb1CwwPXj",
        "outputId": "8863783e-b9cf-4a1c-d9cd-86fcf8352667"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 85])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_mask[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQN1cRuxwQfQ",
        "outputId": "906a5d38-0e77-4e5e-b586-960950d843fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = target[0]"
      ],
      "metadata": {
        "id": "yaebZlrIwd4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_YsfK-S3YiQ",
        "outputId": "560fb92b-7fed-405a-be5a-14b18b8133d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([     1,  38560,  54023,  30743, 103207,  92033,  71293,  96132, 100583,\n",
              "         88557,  18240,  13712,  22970,  60995,  66642,  82970,  18240,  62287,\n",
              "         82394,  42604,   9095,  56881,  12762,  33954,  20988, 107106,   4712,\n",
              "         10009,  16332, 107283,  54023,  97259,  90458,  38045,  11170, 101889,\n",
              "         94238,  85881,      2,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = r * torch.tensor([1])"
      ],
      "metadata": {
        "id": "Fgu-FTu93DAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor([1]).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TThVO1tr3FhL",
        "outputId": "b3622cba-0de9-4783-9b45-9251847d2d36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYnobMe23Rb6",
        "outputId": "d4f487fa-a1e9-41ad-9475-9e5720555c77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([     1,  38560,  54023,  30743, 103207,  92033,  71293,  96132, 100583,\n",
              "         88557,  18240,  13712,  22970,  60995,  66642,  82970,  18240,  62287,\n",
              "         82394,  42604,   9095,  56881,  12762,  33954,  20988, 107106,   4712,\n",
              "         10009,  16332, 107283,  54023,  97259,  90458,  38045,  11170, 101889,\n",
              "         94238,  85881,      2,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
              "             0,      0,      0,      0])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = r.masked_fill(r==0 , 8)"
      ],
      "metadata": {
        "id": "nTAIEbcX3Tds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DpZoywG-6y5",
        "outputId": "fc36ecaf-208c-44fa-c7b0-b729d805a554"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([     1,  38560,  54023,  30743, 103207,  92033,  71293,  96132, 100583,\n",
              "         88557,  18240,  13712,  22970,  60995,  66642,  82970,  18240,  62287,\n",
              "         82394,  42604,   9095,  56881,  12762,  33954,  20988, 107106,   4712,\n",
              "         10009,  16332, 107283,  54023,  97259,  90458,  38045,  11170, 101889,\n",
              "         94238,  85881,      2,      8,      8,      8,      8,      8,      8,\n",
              "             8,      8,      8,      8,      8,      8,      8,      8,      8,\n",
              "             8,      8,      8,      8,      8,      8,      8,      8,      8,\n",
              "             8,      8,      8,      8,      8,      8,      8,      8,      8,\n",
              "             8,      8,      8,      8,      8,      8,      8,      8,      8,\n",
              "             8,      8,      8,      8])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tsJjuwFb_ORV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}